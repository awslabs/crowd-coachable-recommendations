{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51da0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9f137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning==1.9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4afb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134ce153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e ../crowd-coachable-recommendations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f0a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir --ignore-installed -U numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !(cd ../crowd-coachable-recommendations/data/amazon_review_prime_pantry && wget http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_Prime_Pantry.json.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f044843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CCREC_MAX_LENGTH'] = '256'\n",
    "os.environ['CCREC_SIM_TYPE'] = 'dot'\n",
    "os.environ['CCREC_EMBEDDING_TYPE'] = 'mean_pooling'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cb950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f12805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47f18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5da519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing env defaults\n",
      "using   CCREC_EMBEDDING_TYPE=mean_pooling; options: ['cls', 'mu', 'mean', 'mean_pooling', 'mean_layer_norm']\n",
      "using   CCREC_MAX_LENGTH=256; options: None\n",
      "using   CCREC_SIM_TYPE=dot; options: ['cos', 'dot']\n",
      "setting CCREC_TRAIN_MAIN=bmt_main; options: ['bmt_main', 'bbpr_main']\n",
      "setting CCREC_LEGACY_VAE_BUG=0; options: ['0', '1']\n",
      "setting CCREC_DEBUG_SHAP=0; options: ['0', '1']\n",
      "setting CCREC_TRAINING_PRECISION=32; options: ['32', 'bf16']\n",
      "setting CCREC_BBPR_INV_TEMPERATURE=20; options: None\n",
      "setting CCREC_DISPLAY_LENGTH=250; options: None\n",
      "setting CCREC_INIT_ENV_DONE=1; options: ['0', '1']\n",
      "setting CCREC_NON_BLOCKING=1; options: ['0', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/crowd-coachable-recommendations/src/ccrec/__init__.py:44: UserWarning: dot similarity works best with small inv_temperature\n",
      "  warnings.warn(\"dot similarity works best with small inv_temperature\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -n ../crowd-coachable-recommendations/scripts/al_oracle_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c058060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4b271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae200428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d572dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = \"prime_pantry\"\n",
    "SUFFIX='-contriever-dot'\n",
    "N_STEPS=1\n",
    "MODEL_NAME='facebook/contriever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0031f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime_pantry_results_oracle_agent_1.0-contriever-dot\n"
     ]
    }
   ],
   "source": [
    "save_root = \"{}_results_oracle_agent_{}{}\".format(DATA_NAME, ACCURACY_LEVEL, SUFFIX)\n",
    "print(save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a980be",
   "metadata": {},
   "source": [
    "# corpus, queries, qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26b37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_root /home/ec2-user/efs/shared_folder/crowd-coachable-recommendations/data/amazon_review_prime_pantry\n",
      "# items 10812, # brands 1960\n",
      "[['B016OA4X16', 'B0026ILCHE', 'B016KZT8UG', 'B00ICZZCEE', 'B011C0NU3K'], ['B00VH5753C', 'B00RGNGLHU', 'B01CTRJYZI', 'B01487Q3A6', 'B01AUHQJBG'], ['B00I8QZL1G', 'B01GFPHLJ6', 'B00Q8SX51O', 'B010NBK4L0', 'B010VEABOO'], ['B01COSHFG2', 'B01BODRR8Y', 'B016BDOE9C', 'B000SSS5VA', 'B00J2MJ6UM']]\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels, *extra = load_data(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1aa7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(extra):\n",
    "    block_dict, qids_split, item_df = extra\n",
    "    number_of_qid_split_batch = len(qids_split)\n",
    "else:  # standard qids_split creation, though we used previous splits for stability\n",
    "    block_dict = None\n",
    "    number_of_qid_split_batch = 4\n",
    "    qids_split = np.array_split(\n",
    "        np.random.RandomState(42).permutation(list(queries.keys())),\n",
    "        number_of_qid_split_batch\n",
    "    )\n",
    "    qids_split = [s.tolist() for s in qids_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b977cd8",
   "metadata": {},
   "source": [
    "# bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f54f964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm_25 import BM25\n",
    "import tqdm\n",
    "\n",
    "bm25_agent = BM25(b=0.75, k1=1.2).fit(corpus.values())\n",
    "corpus_keys = list(corpus.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2fb24c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9862/9862 [00:36<00:00, 273.07it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_profile = {}\n",
    "for qid in tqdm.tqdm(queries.keys()):\n",
    "    scores = bm25_agent.transform(queries[qid])\n",
    "    if block_dict is not None:\n",
    "        scores[\n",
    "            item_df.index.get_indexer(block_dict[qid])\n",
    "        ] = -1e6\n",
    "    top100 = torch.as_tensor(scores).topk(100).indices.numpy()\n",
    "    bm25_profile[qid] = {\n",
    "        corpus_keys[a]: scores[a]\n",
    "        for a in top100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4c9927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR@1': 0.01014, 'MRR@5': 0.01717, 'MRR@10': 0.01843, 'MRR@100': 0.02046}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = EvaluateRetrieval(None)\n",
    "evaluator.evaluate_custom(\n",
    "    qrels, bm25_profile, [1, 5, 10, 100], metric=\"mrr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6247b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_path = f\"{save_root}/data_iteration_0/ranking_profile_bm25.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beeb4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {os.path.dirname(bm25_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e63e6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bm25_profile, bm25_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c7417",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68064d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy level: 1.0\n",
      "Total number of iterations: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy level:\", ACCURACY_LEVEL)\n",
    "print(\"Total number of iterations:\", number_of_qid_split_batch * N_STEPS)\n",
    "\n",
    "ranking_profile_bm25 = torch.load(bm25_path)\n",
    "\n",
    "# Load initial model\n",
    "model_init_dir = None\n",
    "model = _BertBPR(None, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0c017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1d3ef23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate ranking profile at step: 0\n",
      "MRR@1 : 0.00943\n",
      "MRR@5 : 0.01632\n",
      "MRR@10 : 0.0177\n",
      "MRR@100 : 0.01979\n",
      "Generate training data at step: 0\n",
      "Training model at step: 0\n",
      "Number of training data: 53\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(53, 256) with 53 target events and 261 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 8.533333333333333 ft_num_batches 1.7666666666666666 ct_cycles 1 ft_cycles 4.830188679245283\n",
      "train_set size 53\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006790876388549805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 256,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_26/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006432771682739258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005642890930175781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f90918c520b4a2d832e4a517df9e873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 23. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 30. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['loss', 'loss_step', 'loss_epoch', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "No checkpoints found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.load_state_dict(torch.load(...), strict=False)\n",
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_26/checkpoints/state-dict.pth\n",
      "fit time 63.4s\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(53, 256) with 53 target events and 261 prior scores created!\n",
      "masked False\n",
      "ct_num_batches 8.533333333333333 ft_num_batches 1.7666666666666666 ct_cycles 1 ft_cycles 4.830188679245283\n",
      "Processing 0 | 1\n",
      "transform time 0.6s\n",
      "_assign_topk time 0.0s\n",
      "evaluate_assigned time 0.0s\n",
      "Generate ranking profile at step: 1\n",
      "MRR@1 : 0.01369\n",
      "MRR@5 : 0.0192\n",
      "MRR@10 : 0.02059\n",
      "MRR@100 : 0.02289\n",
      "Generate training data at step: 1\n",
      "Training model at step: 1\n",
      "Number of training data: 113\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(113, 522) with 113 target events and 558 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 17.4 ft_num_batches 3.7666666666666666 ct_cycles 1 ft_cycles 4.619469026548672\n",
      "train_set size 113\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005947589874267578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 522,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_27/checkpoints\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00567936897277832,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00532221794128418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f6430ef6a1466489c25da8ffbe5fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "No checkpoints found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.load_state_dict(torch.load(...), strict=False)\n",
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_27/checkpoints/state-dict.pth\n",
      "fit time 113.3s\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(113, 522) with 113 target events and 558 prior scores created!\n",
      "masked False\n",
      "ct_num_batches 17.4 ft_num_batches 3.7666666666666666 ct_cycles 1 ft_cycles 4.619469026548672\n",
      "Processing 0 | 1\n",
      "transform time 0.9s\n",
      "_assign_topk time 0.0s\n",
      "evaluate_assigned time 0.0s\n",
      "Generate ranking profile at step: 2\n",
      "MRR@1 : 0.01744\n",
      "MRR@5 : 0.02271\n",
      "MRR@10 : 0.02391\n",
      "MRR@100 : 0.02606\n",
      "Generate training data at step: 2\n",
      "Training model at step: 2\n",
      "Number of training data: 166\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(166, 747) with 166 target events and 819 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 24.9 ft_num_batches 5.533333333333333 ct_cycles 1 ft_cycles 4.5\n",
      "train_set size 166\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006693840026855469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 747,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_28/checkpoints\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00599360466003418,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005762815475463867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e263eef4ba4482bae0fe7d3695de429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "No checkpoints found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.load_state_dict(torch.load(...), strict=False)\n",
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_28/checkpoints/state-dict.pth\n",
      "fit time 151.4s\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(166, 747) with 166 target events and 819 prior scores created!\n",
      "masked False\n",
      "ct_num_batches 24.9 ft_num_batches 5.533333333333333 ct_cycles 1 ft_cycles 4.5\n",
      "Processing 0 | 1\n",
      "transform time 1.2s\n",
      "_assign_topk time 0.0s\n",
      "evaluate_assigned time 0.0s\n",
      "Generate ranking profile at step: 3\n",
      "MRR@1 : 0.01967\n",
      "MRR@5 : 0.02369\n",
      "MRR@10 : 0.02504\n",
      "MRR@100 : 0.02725\n",
      "Generate training data at step: 3\n",
      "Training model at step: 3\n",
      "Number of training data: 233\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(233, 1027) with 233 target events and 1150 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 34.233333333333334 ft_num_batches 7.766666666666667 ct_cycles 1 ft_cycles 4.407725321888412\n",
      "train_set size 233\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007489442825317383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 1027,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_29/checkpoints\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005978822708129883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005727291107177734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2c0674450b4bd39f7e61fbcbb7bfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "No checkpoints found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.load_state_dict(torch.load(...), strict=False)\n",
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_29/checkpoints/state-dict.pth\n",
      "fit time 214.4s\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(233, 1027) with 233 target events and 1150 prior scores created!\n",
      "masked False\n",
      "ct_num_batches 34.233333333333334 ft_num_batches 7.766666666666667 ct_cycles 1 ft_cycles 4.407725321888412\n",
      "Processing 0 | 2\n",
      "transform time 1.5s\n",
      "_assign_topk time 0.0s\n",
      "evaluate_assigned time 0.0s\n",
      "Generate ranking profile at step: 4\n",
      "MRR@1 : 0.02322\n",
      "MRR@5 : 0.02693\n",
      "MRR@10 : 0.02824\n",
      "MRR@100 : 0.03056\n"
     ]
    }
   ],
   "source": [
    "for step in range(N_STEPS * number_of_qid_split_batch + 1):\n",
    "    previous_working_dir = f\"{save_root}/data_iteration_{step-1}\"\n",
    "    current_working_dir = f\"{save_root}/data_iteration_{step}\"\n",
    "\n",
    "    if not os.path.exists(current_working_dir):\n",
    "        os.makedirs(current_working_dir)\n",
    "\n",
    "    # generate ranking profile\n",
    "    print(\"Generate ranking profile at step:\", step)\n",
    "    save_path = os.path.join(current_working_dir, \"ranking_profile.pt\")\n",
    "    if os.path.isfile(save_path):\n",
    "        ranking_profile = torch.load(save_path)\n",
    "    else:\n",
    "        with autocast():\n",
    "            ranking_profile = generate_ranking_profile(\n",
    "                model, MODEL_NAME, corpus, queries, qrels, save_path, block_dict)\n",
    "\n",
    "    evaluator = EvaluateRetrieval(None)\n",
    "    mrr = evaluator.evaluate_custom(\n",
    "        qrels, ranking_profile, [1, 5, 10, 100], metric=\"mrr\"\n",
    "    )\n",
    "    for name, value in mrr.items():\n",
    "        print(\"{}\".format(name), \":\", value)\n",
    "\n",
    "    if step >= N_STEPS * number_of_qid_split_batch:\n",
    "        break  # moved here after running\n",
    "\n",
    "    # generate training data\n",
    "    print(\"Generate training data at step:\", step)\n",
    "\n",
    "    train_data = generate_train_data(\n",
    "        qids_split[step % number_of_qid_split_batch],\n",
    "        qrels,\n",
    "        ranking_profile,\n",
    "        ranking_profile_bm25,\n",
    "        list(corpus.keys()),\n",
    "        step,\n",
    "    )\n",
    "\n",
    "    if step > 0:\n",
    "        train_data_prev_dir = os.path.join(\n",
    "            previous_working_dir, \"training_data.pt\"\n",
    "        )\n",
    "        train_data_prev = torch.load(train_data_prev_dir)\n",
    "        train_data = combine_train_data(train_data_prev, train_data)\n",
    "\n",
    "    train_data_dir = os.path.join(current_working_dir, \"training_data.pt\")\n",
    "    torch.save(train_data, train_data_dir)\n",
    "    \n",
    "    # train model\n",
    "    print(\"Training model at step:\", step)\n",
    "    print(\"Number of training data:\", len(train_data))\n",
    "    model = training(\n",
    "        train_data,\n",
    "        NUM_EPOCHS,\n",
    "        model_checkpoint=model_init_dir,\n",
    "        corpus=corpus,\n",
    "        queries=queries,\n",
    "        model_selection=MODEL_NAME,\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        model.model.item_tower.state_dict(),\n",
    "        f'{current_working_dir}/state-dict.pth',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0a643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07547e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c0c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49c63b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_mrr():\n",
    "    for step in range(number_of_qid_split_batch+1):\n",
    "        current_working_dir = f\"{save_root}/data_iteration_{step}\"\n",
    "        ranking_profile = torch.load(current_working_dir + '/ranking_profile.pt')\n",
    "        evaluator = EvaluateRetrieval(None)\n",
    "        mrr = evaluator.evaluate_custom(\n",
    "            qrels, ranking_profile, [1, 5, 10, 100], metric=\"mrr\"\n",
    "        )\n",
    "        for name, value in mrr.items():\n",
    "            print(\"{}\".format(name), \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbe368a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 : 0.00943\n",
      "MRR@5 : 0.01632\n",
      "MRR@10 : 0.0177\n",
      "MRR@100 : 0.01979\n",
      "MRR@1 : 0.01369\n",
      "MRR@5 : 0.0192\n",
      "MRR@10 : 0.02059\n",
      "MRR@100 : 0.02289\n",
      "MRR@1 : 0.01744\n",
      "MRR@5 : 0.02271\n",
      "MRR@10 : 0.02391\n",
      "MRR@100 : 0.02606\n",
      "MRR@1 : 0.01967\n",
      "MRR@5 : 0.02369\n",
      "MRR@10 : 0.02504\n",
      "MRR@100 : 0.02725\n",
      "MRR@1 : 0.02322\n",
      "MRR@5 : 0.02693\n",
      "MRR@10 : 0.02824\n",
      "MRR@100 : 0.03056\n"
     ]
    }
   ],
   "source": [
    "print_all_mrr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357982f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a0025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fc0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1103e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
