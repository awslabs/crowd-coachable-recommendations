{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51da0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9f137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning==1.9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4afb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134ce153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e ../crowd-coachable-recommendations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f0a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir --ignore-installed -U numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f044843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CCREC_MAX_LENGTH'] = '256'\n",
    "os.environ['CCREC_SIM_TYPE'] = 'dot'\n",
    "os.environ['CCREC_EMBEDDING_TYPE'] = 'mean_pooling'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cb950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f12805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47f18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5da519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing env defaults\n",
      "using   CCREC_EMBEDDING_TYPE=mean_pooling; options: ['cls', 'mu', 'mean', 'mean_pooling', 'mean_layer_norm']\n",
      "using   CCREC_MAX_LENGTH=256; options: None\n",
      "using   CCREC_SIM_TYPE=dot; options: ['cos', 'dot']\n",
      "setting CCREC_TRAIN_MAIN=bmt_main; options: ['bmt_main', 'bbpr_main']\n",
      "setting CCREC_LEGACY_VAE_BUG=0; options: ['0', '1']\n",
      "setting CCREC_DEBUG_SHAP=0; options: ['0', '1']\n",
      "setting CCREC_TRAINING_PRECISION=32; options: ['32', 'bf16']\n",
      "setting CCREC_BBPR_INV_TEMPERATURE=20; options: None\n",
      "setting CCREC_DISPLAY_LENGTH=250; options: None\n",
      "setting CCREC_INIT_ENV_DONE=1; options: ['0', '1']\n",
      "setting CCREC_NON_BLOCKING=1; options: ['0', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/crowd-coachable-recommendations/src/ccrec/__init__.py:44: UserWarning: dot similarity works best with small inv_temperature\n",
      "  warnings.warn(\"dot similarity works best with small inv_temperature\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -n ../crowd-coachable-recommendations/scripts/al_oracle_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c058060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4b271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae200428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d572dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = \"prime_pantry\"\n",
    "SUFFIX='-contriever-dot'\n",
    "N_STEPS=1\n",
    "MODEL_NAME='facebook/contriever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0031f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime_pantry_results_oracle_agent_1.0-contriever-dot\n"
     ]
    }
   ],
   "source": [
    "save_root = \"{}_results_oracle_agent_{}{}\".format(DATA_NAME, ACCURACY_LEVEL, SUFFIX)\n",
    "print(save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a980be",
   "metadata": {},
   "source": [
    "# corpus, queries, qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26b37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_root /home/ec2-user/efs/shared_folder/crowd-coachable-recommendations/data/amazon_review_prime_pantry\n",
      "# items 10812, # brands 1960\n",
      "[['B016OA4X16', 'B0026ILCHE', 'B016KZT8UG', 'B00ICZZCEE', 'B011C0NU3K'], ['B00VH5753C', 'B00RGNGLHU', 'B01CTRJYZI', 'B01487Q3A6', 'B01AUHQJBG'], ['B00I8QZL1G', 'B01GFPHLJ6', 'B00Q8SX51O', 'B010NBK4L0', 'B010VEABOO'], ['B01COSHFG2', 'B01BODRR8Y', 'B016BDOE9C', 'B000SSS5VA', 'B00J2MJ6UM']]\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels, *extra = load_data(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc1aa7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(extra):\n",
    "    block_dict, qids_split, item_df = extra\n",
    "    number_of_qid_split_batch = len(qids_split)\n",
    "else:  # standard qids_split creation, though we used previous splits for stability\n",
    "    block_dict = None\n",
    "    number_of_qid_split_batch = 4\n",
    "    qids_split = np.array_split(\n",
    "        np.random.RandomState(42).permutation(list(queries.keys())),\n",
    "        number_of_qid_split_batch\n",
    "    )\n",
    "    qids_split = [s.tolist() for s in qids_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b977cd8",
   "metadata": {},
   "source": [
    "# bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54f964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm_25 import BM25\n",
    "import tqdm\n",
    "\n",
    "bm25_agent = BM25(b=0.75, k1=1.2).fit(corpus.values())\n",
    "corpus_keys = list(corpus.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_profile = {}\n",
    "for qid in tqdm.tqdm(queries.keys()):\n",
    "    scores = bm25_agent.transform(queries[qid])\n",
    "    if block_dict is not None:\n",
    "        scores[\n",
    "            item_df.index.get_indexer(block_dict[qid])\n",
    "        ] = -1e6\n",
    "    top100 = torch.as_tensor(scores).topk(100).indices.numpy()\n",
    "    bm25_profile[qid] = {\n",
    "        corpus_keys[a]: scores[a]\n",
    "        for a in top100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd4c9927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR@1': 0.01014, 'MRR@5': 0.01707, 'MRR@10': 0.01828, 'MRR@100': 0.0203}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = EvaluateRetrieval(None)\n",
    "evaluator.evaluate_custom(\n",
    "    qrels, bm25_profile, [1, 5, 10, 100], metric=\"mrr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6247b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_path = f\"{save_root}/data_iteration_0/ranking_profile_bm25.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beeb4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {os.path.dirname(bm25_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e63e6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bm25_profile, bm25_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c7417",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68064d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy level: 1.0\n",
      "Total number of iterations: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy level:\", ACCURACY_LEVEL)\n",
    "print(\"Total number of iterations:\", number_of_qid_split_batch * N_STEPS)\n",
    "\n",
    "ranking_profile_bm25 = torch.load(bm25_path)\n",
    "\n",
    "# Load initial model\n",
    "model_init_dir = None\n",
    "model = _BertBPR(None, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0c017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3ef23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate ranking profile at step: 0\n",
      "MRR@1 : 0.00943\n",
      "MRR@5 : 0.01632\n",
      "MRR@10 : 0.0177\n",
      "MRR@100 : 0.01979\n",
      "Generate training data at step: 0\n",
      "Training model at step: 0\n",
      "Number of training data: 52\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(52, 251) with 52 target events and 256 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 8.366666666666667 ft_num_batches 1.7333333333333334 ct_cycles 1 ft_cycles 4.826923076923077\n",
      "train_set size 52\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007653951644897461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 251,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_21/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0065250396728515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006032705307006836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef04ea20d8db456d8f8ee36b316f10e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 22. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 30. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['loss', 'loss_step', 'loss_epoch', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "No checkpoints found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.load_state_dict(torch.load(...), strict=False)\n",
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_21/checkpoints/state-dict.pth\n",
      "fit time 64.0s\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(52, 251) with 52 target events and 256 prior scores created!\n",
      "masked False\n",
      "ct_num_batches 8.366666666666667 ft_num_batches 1.7333333333333334 ct_cycles 1 ft_cycles 4.826923076923077\n",
      "Processing 0 | 1\n",
      "transform time 0.6s\n",
      "_assign_topk time 0.0s\n",
      "evaluate_assigned time 0.0s\n",
      "Generate ranking profile at step: 1\n",
      "MRR@1 : 0.01369\n",
      "MRR@5 : 0.0192\n",
      "MRR@10 : 0.02059\n",
      "MRR@100 : 0.02289\n",
      "Generate training data at step: 1\n",
      "Training model at step: 1\n",
      "Number of training data: 111\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(111, 511) with 111 target events and 548 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 17.033333333333335 ft_num_batches 3.7 ct_cycles 1 ft_cycles 4.603603603603604\n",
      "train_set size 111\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0060002803802490234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 511,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/511 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_22/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006096601486206055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006256818771362305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841c8f6c0ba74a8683b0a1993879dde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 21. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "No checkpoints found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.load_state_dict(torch.load(...), strict=False)\n",
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_22/checkpoints/state-dict.pth\n",
      "fit time 109.7s\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(111, 511) with 111 target events and 548 prior scores created!\n",
      "masked False\n",
      "ct_num_batches 17.033333333333335 ft_num_batches 3.7 ct_cycles 1 ft_cycles 4.603603603603604\n",
      "Processing 0 | 1\n",
      "transform time 0.9s\n",
      "_assign_topk time 0.0s\n",
      "evaluate_assigned time 0.0s\n",
      "Generate ranking profile at step: 2\n",
      "MRR@1 : 0.01744\n",
      "MRR@5 : 0.02271\n",
      "MRR@10 : 0.02391\n",
      "MRR@100 : 0.02606\n",
      "Generate training data at step: 2\n",
      "Training model at step: 2\n",
      "Number of training data: 164\n",
      "timing checking for repeated user-item events done . time 0.0s\n",
      "timing inferring training events done . time 0.0s\n",
      "timing creating target_csr timing joining testing events by multi-indexed requests done . time 0.0s\n",
      "done . time 0.0s\n",
      "timing creating prior_score done . time 0.0s\n",
      "timing creating reranking tasks by adding prior_score from target candidates done . time 0.0s\n",
      "Dataset(164, 739) with 164 target events and 810 prior scores created!\n",
      "multiple_nrl alpha=1.0\n",
      "BertMT logs at logs/BertMT/version_23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `Trainer(gpus=4)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=4)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple_nrl alpha=1.0\n",
      "masked False\n",
      "ct_num_batches 24.633333333333333 ft_num_batches 5.466666666666667 ct_cycles 1 ft_cycles 4.5060975609756095\n",
      "train_set size 164\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0052068233489990234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 739,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | item_tower | NaiveItemTower | 109 M \n",
      "----------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.935   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/efs/shared_folder/notebook_prime_pantry/lightning_logs/version_23/checkpoints\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005686044692993164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One of given dataloaders is None and it will be skipped.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005177497863769531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fdaf6fb821488aa7475cbef1bc9c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 14. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "for step in range(N_STEPS * number_of_qid_split_batch + 1):\n",
    "    previous_working_dir = f\"{save_root}/data_iteration_{step-1}\"\n",
    "    current_working_dir = f\"{save_root}/data_iteration_{step}\"\n",
    "\n",
    "    if not os.path.exists(current_working_dir):\n",
    "        os.makedirs(current_working_dir)\n",
    "\n",
    "    # generate ranking profile\n",
    "    print(\"Generate ranking profile at step:\", step)\n",
    "    save_path = os.path.join(current_working_dir, \"ranking_profile.pt\")\n",
    "    if os.path.isfile(save_path):\n",
    "        ranking_profile = torch.load(save_path)\n",
    "    else:\n",
    "        with autocast():\n",
    "            ranking_profile = generate_ranking_profile(\n",
    "                model, MODEL_NAME, corpus, queries, qrels, save_path, block_dict)\n",
    "\n",
    "    evaluator = EvaluateRetrieval(None)\n",
    "    mrr = evaluator.evaluate_custom(\n",
    "        qrels, ranking_profile, [1, 5, 10, 100], metric=\"mrr\"\n",
    "    )\n",
    "    for name, value in mrr.items():\n",
    "        print(\"{}\".format(name), \":\", value)\n",
    "\n",
    "    if step >= N_STEPS * number_of_qid_split_batch:\n",
    "        break  # moved here after running\n",
    "\n",
    "    # generate training data\n",
    "    print(\"Generate training data at step:\", step)\n",
    "\n",
    "    train_data = generate_train_data(\n",
    "        qids_split[step % number_of_qid_split_batch],\n",
    "        qrels,\n",
    "        ranking_profile,\n",
    "        ranking_profile_bm25,\n",
    "        list(corpus.keys()),\n",
    "        step,\n",
    "    )\n",
    "\n",
    "    if step > 0:\n",
    "        train_data_prev_dir = os.path.join(\n",
    "            previous_working_dir, \"training_data.pt\"\n",
    "        )\n",
    "        train_data_prev = torch.load(train_data_prev_dir)\n",
    "        train_data = combine_train_data(train_data_prev, train_data)\n",
    "\n",
    "    train_data_dir = os.path.join(current_working_dir, \"training_data.pt\")\n",
    "    torch.save(train_data, train_data_dir)\n",
    "    \n",
    "    # train model\n",
    "    print(\"Training model at step:\", step)\n",
    "    print(\"Number of training data:\", len(train_data))\n",
    "    model = training(\n",
    "        train_data,\n",
    "        NUM_EPOCHS,\n",
    "        model_checkpoint=model_init_dir,\n",
    "        corpus=corpus,\n",
    "        queries=queries,\n",
    "        model_selection=MODEL_NAME,\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        model.model.item_tower.state_dict(),\n",
    "        f'{current_working_dir}/state-dict.pth',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0a643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07547e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c0c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49c63b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_mrr():\n",
    "    for step in range(number_of_qid_split_batch+1):\n",
    "        current_working_dir = f\"{save_root}/data_iteration_{step}\"\n",
    "        ranking_profile = torch.load(current_working_dir + '/ranking_profile.pt')\n",
    "        evaluator = EvaluateRetrieval(None)\n",
    "        mrr = evaluator.evaluate_custom(\n",
    "            qrels, ranking_profile, [1, 5, 10, 100], metric=\"mrr\"\n",
    "        )\n",
    "        for name, value in mrr.items():\n",
    "            print(\"{}\".format(name), \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbe368a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 : 0.00943\n",
      "MRR@5 : 0.01632\n",
      "MRR@10 : 0.0177\n",
      "MRR@100 : 0.01979\n",
      "MRR@1 : 0.01369\n",
      "MRR@5 : 0.0192\n",
      "MRR@10 : 0.02059\n",
      "MRR@100 : 0.02289\n",
      "MRR@1 : 0.01744\n",
      "MRR@5 : 0.02271\n",
      "MRR@10 : 0.02391\n",
      "MRR@100 : 0.02606\n",
      "MRR@1 : 0.01967\n",
      "MRR@5 : 0.02369\n",
      "MRR@10 : 0.02504\n",
      "MRR@100 : 0.02725\n",
      "MRR@1 : 0.02322\n",
      "MRR@5 : 0.02693\n",
      "MRR@10 : 0.02824\n",
      "MRR@100 : 0.03056\n"
     ]
    }
   ],
   "source": [
    "print_all_mrr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cec194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a0025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fc0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1103e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
